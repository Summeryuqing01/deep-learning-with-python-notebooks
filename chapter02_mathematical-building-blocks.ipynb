{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# The mathematical building blocks of neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## A first look at a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Loading the MNIST dataset in Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 14:59:22.321024: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60000 images, 28 x 28 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The network architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The compilation step**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entropy for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Preparing the image data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gray scale: 0 = white, 255 = black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255 \n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**\"Fitting\" the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch size is the number of samples that you feed to your neural network at each iteration of the training process.\\\n",
    "It determines how often you update the weights of your network based on the gradient of the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2695 - accuracy: 0.9221\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1075 - accuracy: 0.9688\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0716 - accuracy: 0.9786\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0519 - accuracy: 0.9844\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0380 - accuracy: 0.9883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16dcebc10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the model to make predictions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each value in the array represents the probability of the test image being that number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([8.4151415e-09, 1.1198732e-09, 1.1052068e-06, 4.7785497e-06,\n",
       "       7.1779475e-12, 3.8442227e-10, 1.3105383e-13, 9.9999219e-01,\n",
       "       5.2561788e-08, 1.8705397e-06], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digits = test_images[0:10]\n",
    "predictions = model.predict(test_digits)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999922"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Evaluating the model on new data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.0660 - accuracy: 0.9796\n",
      "test_acc: 0.9796000123023987\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"test_acc: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Data representations for neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensors are a generalization of matrices to an arbitrary number of dimensions (note that in the context of tensors, a dimension is often called an axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Scalars (rank-0 tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensor that contains only one number is called a scalar (or scalar tensor, or rank-0 tensor, or 0D tensor).\n",
    "\n",
    "In NumPy, a float32 or float64 number is a scalar tensor (or scalar array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(12)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of axes of a tensor is also called its rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Vectors (rank-1 tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This vector has five entries and so is called a 5-dimensional vector. Don’t confuse a 5D vector with a 5D tensor! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  3,  6, 14,  7])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([12, 3, 6, 14, 7])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Matrices (rank-2 tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entries from the first axis are called the rows, and the entries from the second axis are called the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[5, 78, 2, 34, 0],\n",
    "              [6, 79, 3, 35, 1],\n",
    "              [7, 80, 4, 36, 2]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Rank-3 and higher-rank tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Key attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Number of axes (rank)\n",
    "* Shape\n",
    "* Data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape\n",
    "# 60,000 matrices of 28 × 28 integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Displaying the fourth digit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "digit = train_images[4]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Manipulating tensors in NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "electing specific elements in a tensor is called tensor slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, :, :]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, 0:28, 0:28]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "my_slice = train_images[:, 14:, 14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# crop the images to patches of 14 × 14 pixels centered in the middle\n",
    "my_slice = train_images[:, 7:-7, 7:-7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The notion of data batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "batch = train_images[:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "batch = train_images[128:256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "n = 3\n",
    "batch = train_images[128 * n:128 * (n + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the first axis (axis 0) is called the batch axis or batch dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Real-world examples of data tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Vector data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Timeseries data or sequence data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Image data\n",
    "(samples, height, width, color_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Video data\n",
    "(samples, frames, height, width, color_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## The gears of neural networks: tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Element-wise operations\n",
    "perations that are applied independently to each entry in the tensors being considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2\n",
    "    x = x.copy() # Avoid overwriting the input tensor\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] = max(x[i, j], 0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_add(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert x.shape == y.shape\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[i, j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 0.01 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "x = np.random.random((20, 100))\n",
    "y = np.random.random((20, 100))\n",
    "\n",
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = x + y\n",
    "    z = np.maximum(z, 0.)\n",
    "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 1.64 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = naive_add(x, y)\n",
    "    z = naive_relu(z)\n",
    "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Broadcasting\n",
    "1. Axes (called broadcast axes) are added to the smaller tensor to match the ndim of the larger tensor.\n",
    "\n",
    "2. The smaller tensor is repeated alongside these new axes to match the full shape of the larger tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.random.random((32, 10))\n",
    "y = np.random.random((10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# add an empty first axis to y\n",
    "y = np.expand_dims(y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# repeat y 32 times alongside this new axis\n",
    "Y = np.concatenate([y] * 32, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_add_matrix_and_vector(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.random.random((64, 3, 32, 10))\n",
    "y = np.random.random((32, 10))\n",
    "z = np.maximum(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Tensor product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "x = np.random.random((32,))\n",
    "y = np.random.random((32,))\n",
    "z = np.dot(x, y) # dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_vector_dot(x, y):\n",
    "    assert len(x.shape) == 1\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    z = 0.\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i] += x[i, j] * y[j]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        z[i] = naive_vector_dot(x[i, :], y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_matrix_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 2\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros((x.shape[0], y.shape[1]))\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            row_x = x[i, :]\n",
    "            column_y = y[:, j]\n",
    "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Tensor reshaping\n",
    "Reshaping a tensor means rearranging its rows and columns to match a target shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0., 1.],\n",
    "             [2., 3.],\n",
    "             [4., 5.]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [5.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((6, 1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 300)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros((300, 20))\n",
    "x = np.transpose(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Geometric interpretation of tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A geometric interpretation of deep learning\n",
    "* translation\n",
    "* rotation\n",
    "* scaling\n",
    "* linear transform\n",
    "* affine transform\n",
    "* relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## The engine of neural networks: gradient-based optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### What's a derivative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Derivative of a tensor operation: the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Chaining derivatives: The Backpropagation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The chain rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Automatic differentiation with computation graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The gradient tape in TensorFlow\n",
    "The API through which you can leverage TensorFlow’s powerful automatic differentiation capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.Variable(0.)\n",
    "with tf.GradientTape() as tape:\n",
    "    # Inside the scope, apply some tensor operations to our variable.\n",
    "    y = 2 * x + 3\n",
    "#Use the tape to retrieve the gradient of the output y with respect to our variable x.\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 2.],\n",
       "       [2., 2.]], dtype=float32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_of_y_wrt_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(tf.random.uniform((2, 2)))\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2 * x + 3\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 2.],\n",
       "       [2., 2.]], dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_of_y_wrt_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random.uniform((2, 2)))\n",
    "b = tf.Variable(tf.zeros((2,)))\n",
    "x = tf.random.uniform((2, 2))\n",
    "with tf.GradientTape() as tape:\n",
    "    # matmul is how you say “dot product” in TensorFlow.\n",
    "    y = tf.matmul(x, W) + b\n",
    "grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[1.3244823, 1.3244823],\n",
       "        [0.6862694, 0.6862694]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 2.], dtype=float32)>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_of_y_wrt_W_and_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Looking back at our first example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2630 - accuracy: 0.9238\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1080 - accuracy: 0.9682\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0697 - accuracy: 0.9794\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0504 - accuracy: 0.9848\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0381 - accuracy: 0.9883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16f02c690>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Reimplementing our first example from scratch in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple Dense class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class NaiveDense:\n",
    "    def __init__(self, input_size, output_size, activation):\n",
    "        self.activation = activation\n",
    "        # Create a matrix, W, of shape (input_size, output_size), initialized with random values.\n",
    "        w_shape = (input_size, output_size)\n",
    "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
    "        self.W = tf.Variable(w_initial_value)\n",
    "        # Create a vector, b, of shape (output_size,), initialized with zeros.\n",
    "        b_shape = (output_size,)\n",
    "        b_initial_value = tf.zeros(b_shape)\n",
    "        self.b = tf.Variable(b_initial_value)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        # Apply the forward pass\n",
    "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
    "\n",
    "    @property\n",
    "    # Convenience method for retrieving the layer’s weights\n",
    "    def weights(self):\n",
    "        return [self.W, self.b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple Sequential class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class NaiveSequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    # calls the underlying layers on the inputs\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.layers:\n",
    "           x = layer(x)\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    # easily keep track of the layers’ parameters\n",
    "    def weights(self):\n",
    "       weights = []\n",
    "       for layer in self.layers:\n",
    "           weights += layer.weights\n",
    "       return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = NaiveSequential([\n",
    "    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
    "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
    "])\n",
    "assert len(model.weights) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A batch generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class BatchGenerator:\n",
    "    def __init__(self, images, labels, batch_size=128):\n",
    "        assert len(images) == len(labels)\n",
    "        self.index = 0\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = math.ceil(len(images) / batch_size)\n",
    "\n",
    "    def next(self):\n",
    "        images = self.images[self.index : self.index + self.batch_size]\n",
    "        labels = self.labels[self.index : self.index + self.batch_size]\n",
    "        self.index += self.batch_size\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Running one training step\n",
    "1. Compute the predictions of the model for the images in the batch.\n",
    "\n",
    "2. Compute the loss value for these predictions, given the actual labels.\n",
    "\n",
    "3. Compute the gradient of the loss with regard to the model’s weights.\n",
    "\n",
    "4. Move the weights by a small amount in the direction opposite to the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def one_training_step(model, images_batch, labels_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images_batch)\n",
    "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "            labels_batch, predictions)\n",
    "        average_loss = tf.reduce_mean(per_sample_losses)\n",
    "    gradients = tape.gradient(average_loss, model.weights)\n",
    "    update_weights(gradients, model.weights)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "def update_weights(gradients, weights):\n",
    "    for g, w in zip(gradients, weights):\n",
    "        # assign_sub is the equivalent of -= for TensorFlow variables.\n",
    "        w.assign_sub(g * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "def update_weights(gradients, weights):\n",
    "    optimizer.apply_gradients(zip(gradients, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The full training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def fit(model, images, labels, epochs, batch_size=128):\n",
    "    for epoch_counter in range(epochs):\n",
    "        print(f\"Epoch {epoch_counter}\")\n",
    "        batch_generator = BatchGenerator(images, labels)\n",
    "        for batch_counter in range(batch_generator.num_batches):\n",
    "            images_batch, labels_batch = batch_generator.next()\n",
    "            loss = one_training_step(model, images_batch, labels_batch)\n",
    "            if batch_counter % 100 == 0:\n",
    "                print(f\"loss at batch {batch_counter}: {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "loss at batch 0: 4.32\n",
      "loss at batch 100: 2.29\n",
      "loss at batch 200: 2.23\n",
      "loss at batch 300: 2.10\n",
      "loss at batch 400: 2.20\n",
      "Epoch 1\n",
      "loss at batch 0: 1.91\n",
      "loss at batch 100: 1.91\n",
      "loss at batch 200: 1.84\n",
      "loss at batch 300: 1.72\n",
      "loss at batch 400: 1.81\n",
      "Epoch 2\n",
      "loss at batch 0: 1.58\n",
      "loss at batch 100: 1.60\n",
      "loss at batch 200: 1.52\n",
      "loss at batch 300: 1.42\n",
      "loss at batch 400: 1.50\n",
      "Epoch 3\n",
      "loss at batch 0: 1.32\n",
      "loss at batch 100: 1.36\n",
      "loss at batch 200: 1.25\n",
      "loss at batch 300: 1.21\n",
      "loss at batch 400: 1.27\n",
      "Epoch 4\n",
      "loss at batch 0: 1.13\n",
      "loss at batch 100: 1.17\n",
      "loss at batch 200: 1.05\n",
      "loss at batch 300: 1.04\n",
      "loss at batch 400: 1.10\n",
      "Epoch 5\n",
      "loss at batch 0: 0.98\n",
      "loss at batch 100: 1.03\n",
      "loss at batch 200: 0.91\n",
      "loss at batch 300: 0.92\n",
      "loss at batch 400: 0.99\n",
      "Epoch 6\n",
      "loss at batch 0: 0.87\n",
      "loss at batch 100: 0.92\n",
      "loss at batch 200: 0.81\n",
      "loss at batch 300: 0.83\n",
      "loss at batch 400: 0.90\n",
      "Epoch 7\n",
      "loss at batch 0: 0.79\n",
      "loss at batch 100: 0.84\n",
      "loss at batch 200: 0.73\n",
      "loss at batch 300: 0.76\n",
      "loss at batch 400: 0.83\n",
      "Epoch 8\n",
      "loss at batch 0: 0.73\n",
      "loss at batch 100: 0.77\n",
      "loss at batch 200: 0.67\n",
      "loss at batch 300: 0.71\n",
      "loss at batch 400: 0.78\n",
      "Epoch 9\n",
      "loss at batch 0: 0.68\n",
      "loss at batch 100: 0.71\n",
      "loss at batch 200: 0.62\n",
      "loss at batch 300: 0.66\n",
      "loss at batch 400: 0.74\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "predictions = model(test_images)\n",
    "predictions = predictions.numpy() # Calling .numpy() on a TensorFlow tensor converts it to a NumPy tensor\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "matches = predicted_labels == test_labels\n",
    "print(f\"accuracy: {matches.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary\n",
    "* Tensors form the foundation of modern machine learning systems. They come in various flavors of dtype, rank, and shape.\n",
    "* You can manipulate numerical tensors via tensor operations (such as addition, tensor product, or element-wise multiplication), which can be interpreted as encoding geometric transformations. In general, everything in deep learning is amenable to a geometric interpretation.\n",
    "* Deep learning models consist of chains of simple tensor operations, parameterized by weights, which are themselves tensors. The weights of a model are where its “knowledge” is stored.\n",
    "* Learning means finding a set of values for the model’s weights that minimizes a loss function for a given set of training data samples and their corresponding targets.\n",
    "* Learning happens by drawing random batches of data samples and their targets, and computing the gradient of the model parameters with respect to the loss on the batch. The model parameters are then moved a bit (the magnitude of the move is defined by the learning rate) in the opposite direction from the gradient. This is called mini-batch stochastic gradient descent.\n",
    "* The entire learning process is made possible by the fact that all tensor operations in neural networks are differentiable, and thus it’s possible to apply the chain rule of derivation to find the gradient function mapping the current parameters and current batch of data to a gradient value. This is called backpropagation.\n",
    "* Two key concepts you’ll see frequently in future chapters are loss and optimizers. These are the two things you need to define before you begin feeding data into a model.\n",
    "  * The loss is the quantity you’ll attempt to minimize during training, so it should represent a measure of success for the task you’re trying to solve.\n",
    "  * The optimizer specifies the exact way in which the gradient of the loss will be used to update parameters: for instance, it could be the RMSProp optimizer, SGD with momentum, and so on.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter02_mathematical-building-blocks.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
